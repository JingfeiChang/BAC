# BAC
A novel pruning strategy termed Bilateral Asymptotic Clustering (BAC) channel pruning
With the ongoing advancements in deep learning [1], convolutional neural networks stand out as a pivotal technology. They have surpassed traditional methods in various computer vision domains, including image classification, object detection, and semantic segmentation. However, as tasks grow more complex and performance benchmarks rise, network architectures tend to become increasingly intricate, leading to an expansion in network size. Take ResNet50, for instance, which boasts parameters and FLOPs exceeding 25.56 million and 4.14 billion, respectively, on the ImageNet dataset [2][3]. This escalating demand underscores the criticality of deep neural networks to their intended application. Furthermore, some research have shown the potential presence of redundant parameters within convolutional neural networks [4][16][17], leading to the overfitting during training that ultimately erodes network performance. As we chase heightened performance, it becomes imperative to deliberate on the network's adaptability within real-world usage scenarios.
